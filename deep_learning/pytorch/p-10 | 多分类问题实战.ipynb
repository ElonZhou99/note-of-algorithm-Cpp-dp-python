{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a01c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "#导入Pytorch内置的mnist数据集\n",
    "from torchvision.datasets import mnist\n",
    "# 导入预处理模块\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 200\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "# 定义预处理函数，预处理依次放在Compose函数中\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "# 下载数据，并预处理\n",
    "train_dataset = mnist.MNIST('./data', train=True, transform=transform, download=True)\n",
    "test_dataset = mnist.MNIST('./data', train=False, transform=transform)\n",
    "# dataloader是一个可迭代对象，可以使用迭代器一样使用。\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "'''\n",
    "定义网络\n",
    "'''\n",
    "# 第一层线性层，784维输入，200维输出\n",
    "w1, b1 = torch.randn(200, 784, requires_grad=True),\\\n",
    "         torch.zeros(200, requires_grad=True)\n",
    "# 第二层隐藏层，200维输入，200维输出\n",
    "w2, b2 = torch.randn(200, 200, requires_grad=True),\\\n",
    "         torch.zeros(200, requires_grad=True)\n",
    "# 第三层输出层，200维输入，10维输出\n",
    "w3, b3 = torch.randn(10, 200, requires_grad=True),\\\n",
    "         torch.zeros(10, requires_grad=True)\n",
    "\n",
    "'''\n",
    "前向传播\n",
    "'''\n",
    "def forward(x):\n",
    "    x = x@w1.t() + b1\n",
    "    x = F.relu(x)\n",
    "    x = x@w2.t() + b2\n",
    "    x = F.relu(x)\n",
    "    x = x@w3.t() + b3 # logits，没有经过激活函数或softmax的叫做logits\n",
    "    return x\n",
    "\n",
    "'''\n",
    "定义优化器\n",
    "'''\n",
    "optimizer = optim.SGD([w1, b1, w2, b2, w3, b3], lr=learning_rate)\n",
    "criteon = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.view(-1, 28*28)\n",
    "        \n",
    "        logits = forward(data)\n",
    "        loss = criteon(logits, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9950ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "#导入Pytorch内置的mnist数据集\n",
    "from torchvision.datasets import mnist\n",
    "# 导入预处理模块\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# 导入nn及优化器\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "\"\"\"\n",
    "定义超参数\n",
    "\"\"\"\n",
    "train_batch_size = 64\n",
    "test_batch_size = 128\n",
    "lr = 0.01\n",
    "num_epoches = 20\n",
    "momentum = 0.5\n",
    "\n",
    "\"\"\"\n",
    "下载数据集并预处理\n",
    "\"\"\"\n",
    "# 定义预处理函数，预处理依次放在Compose函数中\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "# 下载数据，并预处理\n",
    "train_dataset = mnist.MNIST('./data', train=True, transform=transform, download=True)\n",
    "test_dataset = mnist.MNIST('./data', train=False, transform=transform)\n",
    "# dataloader是一个可迭代对象，可以使用迭代器一样使用。\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "\"\"\"\n",
    "可视化源数据\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "examples = enumerate(test_loader) # 遍历对象\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "\"\"\"\n",
    "构建模型\n",
    "\"\"\"\n",
    "# 构建网络\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    使用sequential构建网络，Sequential()函数的功能是将网络的层组合到一起\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, n_hidden_3, out_dim):\n",
    "        super(Net, self).__init__()\n",
    "        # nn.BatchNorm1d 批量标准化，更加平滑\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1), nn.BatchNorm1d(n_hidden_1))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2), nn.BatchNorm1d(n_hidden_2))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, n_hidden_3), nn.BatchNorm1d(n_hidden_3))\n",
    "        self.layer4 = nn.Sequential(nn.Linear(n_hidden_3, out_dim))\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "# 实例化网络\n",
    "device = torch.device(\"cpu\")\n",
    "model = Net(28*28, 300, 100, 100, 10)\n",
    "model.to(device) # 发送到上面指定的CPU或者GPU上运算\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "\"\"\"\n",
    "训练模型\n",
    "\"\"\"\n",
    "losses = []\n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    "for epoch in range(num_epoches):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "    # 动态修改学习率\n",
    "    if epoch%5==0:\n",
    "        optimizer.param_groups[0]['lr'] *= 0.5\n",
    "    for img, label in train_loader:\n",
    "        #img = img.to(device)\n",
    "        #label = label.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        # 前向传播\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 记录误差\n",
    "        train_loss += loss.item()\n",
    "        # 计算分类的准确率\n",
    "        _, pred = out.max(1)\n",
    "        num_correct = (pred==label).sum().item()\n",
    "        acc = num_correct / img.shape[0]\n",
    "        train_acc += acc\n",
    "    losses.append(train_loss / len(train_loader))\n",
    "    acces.append(train_acc / len(train_loader))\n",
    "    # 在测试集看效果\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    # 将模型改为预测模式\n",
    "    model.eval()\n",
    "    for img, label in test_loader:\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        out = model(img)\n",
    "        # 计算误差\n",
    "        eval_loss += loss.item()\n",
    "        # 记录准确率\n",
    "        _, pred = out.max(1)\n",
    "        num_correct = (pred==label).sum().item()\n",
    "        acc = num_correct / img.shape[0]\n",
    "        eval_acc += acc\n",
    "    eval_losses.append(eval_loss / len(test_loader))\n",
    "    eval_acces.append(eval_acc / len(test_loader))\n",
    "    print('epoch:{}, Train Loss:{:.4f}, Train Acc:{:4f}, Test Loss:{:.4f}, Test Acc:{:.4f}' .format(epoch, train_loss/len(train_loader), train_acc/len(train_loader), eval_loss/len(test_loader), eval_acc/len(test_loader) ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
